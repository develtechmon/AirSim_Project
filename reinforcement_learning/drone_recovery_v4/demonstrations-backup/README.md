# ğŸš DRONE RECOVERY TRAINING - COMPLETE CHECKLIST

## ğŸ“š **PROJECT OVERVIEW**

**Goal:** Train a drone to recover from flips using curriculum learning

**Approach:** 
1. **Imitation Learning** (30 min) â†’ Learn basic hover
2. **PPO Fine-tuning** (2-3 hours) â†’ Add disturbance recovery
3. **Curriculum RL** (4-6 hours) â†’ Add flip recovery

**Total Time:** 7-10 hours (vs infinite with pure RL!)

---

## ğŸ“‹ **PROGRESS TRACKER**

Copy this section and update as you complete each step:

```
STAGE 1: IMITATION LEARNING (DAY 1)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
[x] Step 1: PID Expert Test
    Date: ___________
    Result: EXCELLENT âœ…
    Mean altitude: 10.193m
    Std deviation: 0.054m

[ ] Step 2: Collect Demonstrations (Quick Test)
    Date: ___________
    Command: python collect_demonstrations.py --episodes 100 --steps 200
    Avg Reward: _______
    File size: _______ MB
    Status: PASS âœ… / FAIL âŒ

[ ] Step 2B: Collect Full Dataset (Optional)
    Date: ___________
    Command: python collect_demonstrations.py --episodes 2000 --steps 200
    Avg Reward: _______
    File size: _______ MB
    Time: ~60 minutes

[ ] Step 3: Train Neural Network
    Date: ___________
    Command: python train_imitation.py
    Training loss: _______
    Validation loss: _______
    Time: _______ minutes
    Status: PASS âœ… / FAIL âŒ

[ ] Step 4: Test Learned Policy
    Date: ___________
    Command: python test_hover_policy.py
    Success rate: _______
    Avg distance: _______ m
    Status: PASS âœ… / FAIL âŒ

STAGE 2: DISTURBANCE RECOVERY (WEEK 1)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
[ ] Step 5: Setup Stage 2 Environment
    Date: ___________
    Files created: train_stage2_disturbance.py
                   drone_hover_disturbance_env.py

[ ] Step 6: Train PPO with Disturbances
    Date: ___________
    Command: python train_stage2_disturbance.py
    Training time: _______ hours
    Episodes: _______
    Status: PASS âœ… / FAIL âŒ

[ ] Step 7: Test Disturbance Recovery
    Date: ___________
    Success rate with wind: _______
    Recovery time: _______ seconds
    Status: PASS âœ… / FAIL âŒ

STAGE 3: FLIP RECOVERY (WEEK 2)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
[ ] Step 8: Setup Flip Recovery Environment
    Date: ___________
    Files created: train_stage3_flip.py
                   drone_flip_recovery_env.py

[ ] Step 9A: Train 30Â° Flip Recovery
    Date: ___________
    Training time: _______ hours
    Success rate: _______

[ ] Step 9B: Train 60Â° Flip Recovery
    Date: ___________
    Training time: _______ hours
    Success rate: _______

[ ] Step 9C: Train 90Â° Flip Recovery
    Date: ___________
    Training time: _______ hours
    Success rate: _______

[ ] Step 9D: Train 180Â° Flip Recovery
    Date: ___________
    Training time: _______ hours
    Success rate: _______

[ ] Step 10: Final Test - Full Flip Recovery
    Date: ___________
    180Â° flip success: _______
    Recovery time: _______ seconds
    Status: PASS âœ… / FAIL âŒ

ğŸ‰ FINAL GOAL ACHIEVED: [ ]
    Date: ___________
    Total time invested: _______ hours
```

---

## ğŸš€ **STAGE 1: IMITATION LEARNING (TODAY)**

### **âœ… Step 1: Test PID Expert (5 minutes)**

**Command:**
```bash
python pid_expert.py
```

**Expected Output:**
```
Mean altitude: 10.001m (target: 10.0m)
Std deviation: 0.012m
Max error: 0.024m
âœ… PID Expert is EXCELLENT! Ready to generate demonstrations.
```

**Success Criteria:**
- âœ… Mean altitude: 9.9 - 10.1m
- âœ… Std deviation: < 0.3m
- âœ… Max error: < 0.5m
- âœ… Message: "EXCELLENT!"

**If Failed:** Adjust PID gains in `pid_expert.py` (lines 78-80)

---

### **âœ… Step 2: Collect Demonstrations (10-60 minutes)**

**Quick Test (10 minutes):**
```bash
python collect_demonstrations.py --episodes 100 --steps 200
```

**Full Dataset (60 minutes):**
```bash
python collect_demonstrations.py --episodes 2000 --steps 200
```

**Expected Output:**
```
Episode  100/100 | Avg Reward:  1639.8 | Speed: 3.5 eps/min

ğŸ“Š Dataset Statistics:
   Total samples: 20,000 (or 400,000 for full)
   Mean episode reward: 1639.8
   Std episode reward: 89.3
   Collection time: 28.7 minutes

ğŸ’¾ Saved to: ./demonstrations/expert_demonstrations.pkl
```

**Success Criteria:**
- âœ… Avg Reward > 1500
- âœ… Std reward < 200
- âœ… File created successfully

**If Failed:** Go back to Step 1, fix PID

---

### **âœ… Step 3: Train Neural Network (30 minutes)**

**Command:**
```bash
python train_imitation.py --dataset ./demonstrations/expert_demonstrations.pkl
```

**Expected Output:**
```
Epoch   1/100 | Train Loss: 2.456 | Val Loss: 2.389
Epoch  10/100 | Train Loss: 0.421 | Val Loss: 0.412
Epoch  50/100 | Train Loss: 0.054 | Val Loss: 0.061
Epoch 100/100 | Train Loss: 0.023 | Val Loss: 0.029

âœ… Training Complete!
ğŸ’¾ Model saved: ./models/hover_policy.pth

Final Performance:
   Training Loss: 0.023
   Validation Loss: 0.029
   Predicted Success Rate: 95%+
```

**Success Criteria:**
- âœ… Final loss < 0.05
- âœ… Validation loss < 0.06
- âœ… Model file created

**If Failed:** Collect more data or train longer

---

### **âœ… Step 4: Test Learned Policy (5 minutes)**

**Command:**
```bash
python test_hover_policy.py
```

**Expected Output:**
```
Episode  1/10 | Steps: 500 | Success: âœ… | Avg Distance: 0.31m
Episode  2/10 | Steps: 500 | Success: âœ… | Avg Distance: 0.28m
...
Episode 10/10 | Steps: 500 | Success: âœ… | Avg Distance: 0.26m

ğŸ“Š TEST RESULTS
Success Rate: 90% (9/10 episodes)
Average Episode Length: 497.8 steps
Average Distance from Target: 0.30m

âœ… Policy successfully learned to hover!
```

**Success Criteria:**
- âœ… Success rate > 80%
- âœ… Avg episode length > 400 steps
- âœ… Avg distance < 0.5m

**If Failed:** 
- 50-80% success â†’ Collect more data (2000 episodes)
- <50% success â†’ Debug training process

---

## ğŸš€ **STAGE 2: DISTURBANCE RECOVERY (WEEK 1)**

### **âœ… Step 5: Setup Stage 2 Environment**

**Files Needed:**
- `train_stage2_disturbance.py` (creates PPO trainer with pretrained weights)
- `drone_hover_disturbance_env.py` (adds wind to environment)

**What It Does:**
- Loads Stage 1 hover policy
- Adds random wind disturbances
- Fine-tunes with PPO

---

### **âœ… Step 6: Train with Disturbances (2-3 hours)**

**Command:**
```bash
python train_stage2_disturbance.py
```

**Expected Output:**
```
Loading pretrained hover policy: hover_policy.pth
Initializing PPO with pretrained weights...

Training with wind disturbances...

Episode 100 | Avg Return: 1234.5 | Success with wind: 65%
Episode 500 | Avg Return: 1567.8 | Success with wind: 80%
Episode 1000 | Avg Return: 1621.3 | Success with wind: 85%

âœ… Training complete!
ğŸ’¾ Model saved: ./models/hover_disturbance_policy.zip
```

**Success Criteria:**
- âœ… Success with wind > 70%
- âœ… Can recover from gusts < 5s

---

### **âœ… Step 7: Test Disturbance Recovery (5 minutes)**

**Command:**
```bash
python test_stage2_policy.py
```

**Success Criteria:**
- âœ… Success rate with wind > 70%
- âœ… Recovery time < 5 seconds
- âœ… Maintains altitude Â±1m

---

## ğŸš€ **STAGE 3: FLIP RECOVERY (WEEK 2)**

### **âœ… Step 8: Setup Flip Recovery Environment**

**Files Needed:**
- `train_stage3_flip.py` (curriculum learning script)
- `drone_flip_recovery_env.py` (starts drone flipped)

---

### **âœ… Step 9: Curriculum Training (4-6 hours)**

**9A: 30Â° Flips (1 hour)**
```bash
python train_stage3_flip.py --flip-angle 30 --timesteps 250000
```

**9B: 60Â° Flips (1 hour)**
```bash
python train_stage3_flip.py --flip-angle 60 --timesteps 250000 --load-model flip_30deg.zip
```

**9C: 90Â° Flips (1-2 hours)**
```bash
python train_stage3_flip.py --flip-angle 90 --timesteps 500000 --load-model flip_60deg.zip
```

**9D: 180Â° Flips (2-3 hours)**
```bash
python train_stage3_flip.py --flip-angle 180 --timesteps 750000 --load-model flip_90deg.zip
```

**Success Criteria Per Angle:**
- 30Â°: >90% success
- 60Â°: >80% success
- 90Â°: >70% success
- 180Â°: >60% success

---

### **âœ… Step 10: Final Test (5 minutes)**

**Command:**
```bash
python test_flip_recovery.py --flip-angle 180
```

**Expected Output:**
```
Testing 180Â° flip recovery...

Episode  1/10 | Success: âœ… | Recovery time: 8.2s
Episode  2/10 | Success: âœ… | Recovery time: 7.5s
...
Episode 10/10 | Success: âŒ | Failed to recover

ğŸ“Š FINAL RESULTS
Success Rate: 70% (7/10)
Avg Recovery Time: 7.8 seconds

ğŸ‰ GOAL ACHIEVED! Drone can recover from 180Â° flips!
```

**Success Criteria:**
- âœ… 180Â° recovery > 60%
- âœ… Recovery time < 10 seconds

---

## ğŸ“‚ **FILE STRUCTURE**

```
drone_recovery_v3/
â”‚
â”œâ”€â”€ demonstrations/                    # Expert data
â”‚   â”œâ”€â”€ expert_demonstrations.pkl      # Full dataset
â”‚   â””â”€â”€ checkpoint_*.pkl               # Backup checkpoints
â”‚
â”œâ”€â”€ models/                            # Trained models
â”‚   â”œâ”€â”€ hover_policy.pth               # Stage 1: Imitation
â”‚   â”œâ”€â”€ hover_disturbance_policy.zip   # Stage 2: PPO + wind
â”‚   â”œâ”€â”€ flip_30deg.zip                 # Stage 3: 30Â° recovery
â”‚   â”œâ”€â”€ flip_60deg.zip                 # Stage 3: 60Â° recovery
â”‚   â”œâ”€â”€ flip_90deg.zip                 # Stage 3: 90Â° recovery
â”‚   â””â”€â”€ flip_180deg.zip                # Stage 3: 180Â° recovery (FINAL!)
â”‚
â”œâ”€â”€ logs/                              # Training logs
â”‚   â”œâ”€â”€ stage1/
â”‚   â”œâ”€â”€ stage2/
â”‚   â””â”€â”€ stage3/
â”‚
â”œâ”€â”€ pid_expert.py                      # Step 1: PID controller
â”œâ”€â”€ collect_demonstrations.py          # Step 2: Data collection
â”œâ”€â”€ train_imitation.py                 # Step 3: BC training
â”œâ”€â”€ test_hover_policy.py               # Step 4: Test Stage 1
â”‚
â”œâ”€â”€ train_stage2_disturbance.py        # Step 6: Stage 2 training
â”œâ”€â”€ drone_hover_disturbance_env.py     # Step 6: Wind environment
â”œâ”€â”€ test_stage2_policy.py              # Step 7: Test Stage 2
â”‚
â”œâ”€â”€ train_stage3_flip.py               # Step 9: Stage 3 training
â”œâ”€â”€ drone_flip_recovery_env.py         # Step 9: Flip environment
â”œâ”€â”€ test_flip_recovery.py              # Step 10: Test Stage 3
â”‚
â”œâ”€â”€ COMPLETE_SOLUTION.md               # Full roadmap
â”œâ”€â”€ QUICK_START.md                     # Getting started guide
â””â”€â”€ README.md                          # This file
```

---

## ğŸ“ **KEY CONCEPTS**

### **What is Imitation Learning?**
Learning by copying an expert (PID controller) rather than trial-and-error.

### **What is Behavioral Cloning?**
Supervised learning on expert demonstrations (state â†’ action pairs).

### **What is Curriculum Learning?**
Starting easy (30Â° flips) and gradually increasing difficulty (180Â° flips).

### **Why This Approach Works:**
- âœ… 10-20x faster than pure RL
- âœ… Guaranteed to learn basic hover
- âœ… Each stage builds on previous
- âœ… Research-proven method

---

## ğŸ“Š **EXPECTED TIME INVESTMENT**

```
Stage 1 (Imitation Learning):
  Step 1: PID Test .................... 5 min
  Step 2: Data Collection ............. 60 min
  Step 3: Training .................... 30 min
  Step 4: Testing ..................... 5 min
  TOTAL: ~2 hours

Stage 2 (Disturbance Recovery):
  Step 5: Setup ....................... 5 min
  Step 6: Training .................... 2-3 hours
  Step 7: Testing ..................... 5 min
  TOTAL: ~3 hours

Stage 3 (Flip Recovery):
  Step 8: Setup ....................... 5 min
  Step 9: Curriculum Training ......... 4-6 hours
  Step 10: Final Testing .............. 5 min
  TOTAL: ~6 hours

GRAND TOTAL: 11 hours
(vs infinite hours with pure RL!)
```

---

## ğŸš¨ **DECISION POINTS**

### **After Step 2:**
- âœ… Avg Reward > 1500 â†’ Proceed to Step 3
- âš ï¸ Avg Reward 1000-1500 â†’ Retry with 2000 episodes
- âŒ Avg Reward < 1000 â†’ Fix PID (Step 1)

### **After Step 4:**
- âœ… Success > 80% â†’ Proceed to Stage 2
- âš ï¸ Success 50-80% â†’ Collect more data
- âŒ Success < 50% â†’ Debug training

### **After Step 7:**
- âœ… Success > 70% â†’ Proceed to Stage 3
- âš ï¸ Success 50-70% â†’ Train longer
- âŒ Success < 50% â†’ Retrain Stage 2

### **After Step 10:**
- âœ… Success > 60% â†’ **MISSION ACCOMPLISHED!** ğŸ‰
- âš ï¸ Success 40-60% â†’ Train 180Â° longer
- âŒ Success < 40% â†’ Review curriculum

---

## ğŸ’¡ **TROUBLESHOOTING**

### **Problem: PID doesn't hover well**
**Solution:** Edit `pid_expert.py` lines 78-80, adjust gains:
- Increase `kp` for faster response
- Increase `kd` to reduce oscillation
- Decrease `ki` if unstable

### **Problem: Data collection very slow**
**Solution:** 
- Check AirSim isn't lagging
- Reduce episodes: `--episodes 500`
- Reduce steps: `--steps 150`

### **Problem: Training loss not decreasing**
**Solution:**
- Collect more data (2000 episodes)
- Train longer (200 epochs)
- Check PID expert quality

### **Problem: Learned policy drifts**
**Solution:**
- Need more diverse data
- Check PID is tuned well
- Add noise to starting positions

---

## ğŸ“š **REFERENCES**

Research papers that inspired this approach:
1. "Imitation Learning of Complex Behaviors for Multiple Drones" (2023)
2. "Supervised Reinforcement Learning for Drone Hovering" (2024)
3. "Learning-based Quadcopter Controller with Extreme Adaptation" (2023)
4. "End-to-end Neural Network Based Optimal Quadcopter Control" (2023)

---

## ğŸ‰ **SUCCESS CRITERIA**

You've achieved the goal when:
- âœ… Drone can hover at 10m (95% success)
- âœ… Drone recovers from wind gusts (80% success)
- âœ… Drone recovers from 180Â° flips (60%+ success)
- âœ… Total training time < 12 hours

---

## ğŸ“ **NOTES SECTION**

Use this space for your observations:

```
Date: ___________
Step: ___________
Observations:




Issues encountered:




Solutions tried:




Next steps:




```

---

**Download this file and track your progress! Good luck!** ğŸšâœ¨

**Last Updated:** November 2024
**Version:** 1.0